{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e348a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 1] í™˜ê²½ ì„¤ì •\n",
    "# Colab í™˜ê²½ì— ë§ì¶° í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install \"numpy<2.0\" \"scipy<1.13\" ultralytics scikit-learn opencv-python-headless -U -q\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "\n",
    "print(f\"âœ… Setup Complete\")\n",
    "print(f\"Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: GPU not detected. Go to Runtime > Change runtime type > T4 GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1168a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 2] ë°ì´í„°ì…‹ ë° ëª¨ë¸ ì¤€ë¹„\n",
    "REPO_NAME = \"MCA-Appendix\"\n",
    "REPO_URL = \"https://github.com/ICT-Top-Bottom/MCA-Appendix.git\"\n",
    "REPO_DIR = f\"/content/{REPO_NAME}\"  # Colab ê²½ë¡œë¡œ ë³€ê²½ (/content/)\n",
    "\n",
    "# 1. ë¦¬í¬ì§€í† ë¦¬ í™•ì¸ (ì—†ìœ¼ë©´ í´ë¡ , ìˆìœ¼ë©´ ìœ ì§€)\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"ğŸ“¥ Cloning repository from {REPO_URL}...\")\n",
    "    !git clone {REPO_URL}\n",
    "else:\n",
    "    print(f\"âœ… Repository already exists at {REPO_DIR}. Skipping clone.\")\n",
    "\n",
    "# 2. data.yaml ê²½ë¡œë¥¼ Colab ì ˆëŒ€ ê²½ë¡œë¡œ ìˆ˜ì •\n",
    "DATA_YAML_PATH = f\"{REPO_DIR}/data.yaml\"\n",
    "BEST_PT_PATH = f\"{REPO_DIR}/best.pt\"\n",
    "\n",
    "if os.path.exists(DATA_YAML_PATH):\n",
    "    with open(DATA_YAML_PATH, 'r') as f:\n",
    "        data_config = yaml.safe_load(f)\n",
    "\n",
    "    # ë°ì´í„°ì…‹ ì ˆëŒ€ ê²½ë¡œ ì„¤ì • (Colab ê²½ë¡œ)\n",
    "    data_config['path'] = f\"{REPO_DIR}/dataset\"\n",
    "    data_config['train'] = \"train/images\"\n",
    "    data_config['val'] = \"valid/images\"\n",
    "    data_config['test'] = \"test/images\"\n",
    "\n",
    "    with open(DATA_YAML_PATH, 'w') as f:\n",
    "        yaml.dump(data_config, f)\n",
    "    \n",
    "    print(f\"âœ… data.yaml configured: {DATA_YAML_PATH}\")\n",
    "else:\n",
    "    print(\"âŒ Error: data.yaml not found. Check repository structure.\")\n",
    "\n",
    "print(f\"âš–ï¸ Model Weights: {BEST_PT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 3] ëª¨ë¸ í•™ìŠµ (Training)\n",
    "# ë…¼ë¬¸ì— ì œì•ˆëœ ì„¤ì •ìœ¼ë¡œ í•™ìŠµì„ ì¬í˜„í•©ë‹ˆë‹¤.\n",
    "# í•™ìŠµì„ ê±´ë„ˆë›°ê³  ë°”ë¡œ ì¶”ë¡ í•˜ë ¤ë©´ ì´ ì…€ì€ ì‹¤í–‰í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.\n",
    "\n",
    "print(\"ğŸš€ Training Started...\")\n",
    "model = YOLO('yolo11s-seg.pt')\n",
    "\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    \n",
    "    # --- System Config (Kaggle T4 x2 Optimized) ---\n",
    "    device=0,\n",
    "    batch=8,                # 1280px ë©”ëª¨ë¦¬ ìµœì ê°’ (OOM ë°©ì§€)\n",
    "    epochs=200,\n",
    "    patience=40,\n",
    "    \n",
    "    # --- Proposed Method Config ---\n",
    "    imgsz=1280,             # High-Resolution (í•µì‹¬)\n",
    "    multi_scale=True,\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.001,\n",
    "    \n",
    "    # --- Segmentation Tuning ---\n",
    "    mask_ratio=4,           # Wireframe ë­‰ê°œê¸° (ì„±ëŠ¥ í•µì‹¬)\n",
    "    overlap_mask=True,\n",
    "    close_mosaic=10,\n",
    "    \n",
    "    # --- Loss & Augmentation ---\n",
    "    cls=0.5,\n",
    "    box=7.5,\n",
    "    mixup=0.15,             # Combined Cart í•™ìŠµìš©\n",
    "    mosaic=1.0,\n",
    "    degrees=15.0,\n",
    "    \n",
    "    # --- Reproducibility ---\n",
    "    seed=42,\n",
    "    deterministic=True,\n",
    "    \n",
    "    project='runs/train',\n",
    "    name='MCA-CartSeg_Reproduction',\n",
    "    save=True,\n",
    "    plots=True\n",
    ")\n",
    "print(\"âœ… Training Finished! Best model saved at runs/train/HR-CartSeg_Reproduction/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 4] ì¶”ë¡  ì‹¤í–‰ ë° ì‹œê°í™” (Inference)\n",
    "# í•™ìŠµëœ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ GitHubì—ì„œ ë°›ì€ best.ptë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# 1. ëª¨ë¸ ë¡œë“œ\n",
    "if os.path.exists('runs/train/MCA-CartSeg_Reproduction/weights/best.pt'):\n",
    "    model_path = 'runs/train/MCA-CartSeg_Reproduction/weights/best.pt'\n",
    "    print(f\"âœ… Loading Trained Model: {model_path}\")\n",
    "else:\n",
    "    model_path = BEST_PT\n",
    "    print(f\"âœ… Loading Pre-trained Model (Repo): {model_path}\")\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# 2. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì¶”ë¡ \n",
    "test_img_path = f'{REPO_DIR}/dataset/test/images/test1.jpg' # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì‹œ\n",
    "\n",
    "if os.path.exists(test_img_path):\n",
    "    print(f\"ğŸ” Running Inference on: {test_img_path}\")\n",
    "    results = model.predict(test_img_path, imgsz=1280, conf=0.25)\n",
    "    \n",
    "    # ê²°ê³¼ ì‹œê°í™”\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(results[0].plot(), cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Inference Result (Conf > 0.25)\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"âŒ Test image not found. Please check dataset path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 5] ë™ì˜ìƒ íŒŒì¼ ì²˜ë¦¬ (Optional)\n",
    "# ë™ì˜ìƒ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ì§€ì •í•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”.\n",
    "\n",
    "def run_inference_on_video(video_path, model_path):\n",
    "    print(f\"ğŸ¬ Processing Video: {video_path}...\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # ë¹„ë””ì˜¤ ì •ë³´\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥ìš© Writer\n",
    "    output_path = 'output_result.mp4'\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    \n",
    "    frame_count = 0\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "        \n",
    "        # ì¶”ë¡  (Retina Masksë¡œ ê³ í™”ì§ˆ ìœ ì§€)\n",
    "        results = model.predict(frame, conf=0.25, retina_masks=True, verbose=False)\n",
    "        annotated_frame = results[0].plot() \n",
    "        \n",
    "        out.write(annotated_frame)\n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Processing frame {frame_count}...\")\n",
    "            \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"âœ… Video processing completed! Saved to {output_path}\")\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ (íŒŒì¼ ê²½ë¡œ ìˆ˜ì • í•„ìš”)\n",
    "# run_inference_on_video('/kaggle/input/test-video.mp4', model_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
